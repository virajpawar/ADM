{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Nasa Confirms Earth Will Experience 6 Days of...</td>\n",
       "      <td>154</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accused Boston Marathon Bomber Severely Injure...</td>\n",
       "      <td>962</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Identity of ISIS terrorist known as 'Jihadi Jo...</td>\n",
       "      <td>2033</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banksy 'Arrested &amp; Real Identity Revealed' Is ...</td>\n",
       "      <td>1739</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>British Aid Worker Confirmed Murdered By ISIS</td>\n",
       "      <td>882</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712    discuss\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158    discuss\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137   disagree\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034   disagree\n",
       "4  Spider burrowed through tourist's stomach and ...     1923      agree\n",
       "5  'Nasa Confirms Earth Will Experience 6 Days of...      154    discuss\n",
       "6  Accused Boston Marathon Bomber Severely Injure...      962  unrelated\n",
       "7  Identity of ISIS terrorist known as 'Jihadi Jo...     2033      agree\n",
       "8  Banksy 'Arrested & Real Identity Revealed' Is ...     1739      agree\n",
       "9      British Aid Worker Confirmed Murdered By ISIS      882      agree"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "stance = pd.read_csv(\"//Users//kelvin//Downloads//data.csv\", header=0,)\n",
    "stance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stance.drop('Body ID' , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline   Stance  label_num\n",
       "0  Police find mass graves with at least '15 bodi...  discuss          2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agree        12451\n",
       "disagree     12513\n",
       "discuss      12527\n",
       "unrelated    12481\n",
       "Name: Stance, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "stance.Stance.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972,)\n",
      "(49972,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = stance.Headline\n",
    "y = stance.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline    Stance  label_num\n",
       "0  Police find mass graves with at least '15 bodi...   discuss          2\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...   discuss          2\n",
       "2  Christian Bale passes on role of Steve Jobs, a...  disagree          1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "stance['label_num'] = stance.Stance.map({'agree':0, 'disagree':1, 'discuss':2, 'unrelated':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_bias_con = stance[(stance.label_num==0) | (stance.label_num==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24964, 3)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bias_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = news_bias_con.Headline\n",
    "y = news_bias_con.label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18723,)\n",
      "(6241,)\n",
      "(18723,)\n",
      "(6241,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37479x3354 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 407732 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12493x3354 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 135517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 ms, sys: 3.91 ms, total: 17.3 ms\n",
      "Wall time: 19.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\n",
    "my_forest = forest.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574801046841\n"
     ]
    }
   ],
   "source": [
    "print(my_forest.score(X_train_dtm, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2497398543184183"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1421, 1642],\n",
       "       [1495, 1683]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.50      0.50      3063\n",
      "          1       0.51      0.50      0.51      3178\n",
      "\n",
      "avg / total       0.50      0.50      0.50      6241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36982    Lego letter from the 1970s still offers a powe...\n",
       "16109    'Sex attacker' has penis cut off with a cleave...\n",
       "39426    In Kim Jong Un's absence, his sister may rule....\n",
       "11378    Apple Watch to Be Shower-Proof, Have 100,000 A...\n",
       "17517         Cheese addiction breaks Kim Jong-un's ankles\n",
       "15078    Officials Refute Iraqi Media Reports That ISIS...\n",
       "23091    Kim Jong-un: obese leader 'fractured both ankles'\n",
       "8704      U.S. arms airdrop fell into ISIS hands: Pentagon\n",
       "39231    North Korean leader Kim Jong-un to open restau...\n",
       "39992    Shots Heard In Alleged Brown Shooting Recordin...\n",
       "11506    Officials Refute Iraqi Media Reports That ISIS...\n",
       "42965    New policy could reduce marijuana possession a...\n",
       "37679    Tropical spider burrows under man's skin throu...\n",
       "45004    Christian Bale in Talks to Play Steve Jobs (Ex...\n",
       "8643     CNN Broadcasts Purported Audio Containing Guns...\n",
       "26260    6 hidden mass graves may hold missing Mexican ...\n",
       "18703    ISIS pays tribute to its 'Cub of Baghdadi' chi...\n",
       "6030     Apple Orders More Than 5 Million Watches for I...\n",
       "16342    Son pays off his parents' mortgage in a heartw...\n",
       "6985         ISIL Beheads American Photojournalist in Iraq\n",
       "49907                Tom Brokaw wants Brian Williams fired\n",
       "36945    David Haines Beheaded By ISIS, Execution Video...\n",
       "28955    Vice CEO Shane Smith reportedly spent $300,000...\n",
       "39122    Shots Heard In Alleged Brown Shooting Recordin...\n",
       "30849    Suspected meteorite leaves crater in Managua, ...\n",
       "7099     McDonald’s Will Stop Serving Overweight Custom...\n",
       "44285    David Haines Beheaded By ISIS, Execution Video...\n",
       "47490    Christian Bale in Talks to Star in Sony's Stev...\n",
       "8996     BREAKING: \"Brat Pack\" Judd Nelson Found Dead i...\n",
       "13582    WHO says reports of suspected Ebola cases in I...\n",
       "                               ...                        \n",
       "44028    BREAKING: Islamic State, in video, beheads Ame...\n",
       "6163     Islamic State Training Pilots in Military Jets...\n",
       "11588       Soldier shot near Canadian parliament building\n",
       "8992     BREAKING: ISIS Beheads American Journalist Jam...\n",
       "45256           In Vogue vs Rats War, the Rats Are Winning\n",
       "38908    Eyewitness Says Viral Video of Homeless Man Wa...\n",
       "31542    Reports: Islamic State uses chlorine gas again...\n",
       "10799    Mexican cartel leader kills self; bodies in gr...\n",
       "28079    Kim Jong-un relying on ‘cobra wine’ after prob...\n",
       "43193    Kim Jong ill? Analysts say 27-year-old sister ...\n",
       "33432    Guantanamo detainee freed in Bowe Bergdahl swa...\n",
       "36801    Anna Wintour 'refuses to work at new World Tra...\n",
       "26750    Catholic Priest Claims God Is Female After Cli...\n",
       "3003     The Man Who Says Comcast Got Him Fired Has Fil...\n",
       "33436    ISIS Video Purports To Show Beheading Of Briti...\n",
       "28435    Nigerians doubtful of girls' release after Bok...\n",
       "26028    Daash Ebola transferred to Mosul {Google Trans...\n",
       "11196    'Nasa Confirms Earth Will Experience 6 Days of...\n",
       "46888    Ottawa shooting: Sergeant-at-arms Kevin Vicker...\n",
       "27511    Apple to Take Reservations for Trying On Apple...\n",
       "14924    Iraqi Official Dismisses ‘Unfounded’ Reports T...\n",
       "34200    Teacher sex tape exposed as a FAKE after inter...\n",
       "31188    Kim Yo Jong, Kim Jong-Un’s Sister, Takes Contr...\n",
       "43048    Islamic State training fighter pilots in captu...\n",
       "17427    Kim Jong-Un 'in hospital with two fractured an...\n",
       "34865    ISIS Border Crisis: DHS Chief Says Terrorists ...\n",
       "34119    North Korea denies reports Kim Jong-un is to o...\n",
       "35580    IRAQI AND KURDISH MEDIA REPORTS: ISIS FIGHTERS...\n",
       "21557    In Kim Jong Un's absence, his sister may rule....\n",
       "17742                                      Texas, Hold 'Em\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives (ham incorrectly classified as spam)\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3219063 ,  0.43586059,  0.17301991, ...,  0.00074338,\n",
       "        0.73071962,  0.71983502])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49810811638207253"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 341 ms, sys: 6.85 ms, total: 348 ms\n",
      "Wall time: 349 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50056892,  0.46088328,  0.46005781, ...,  0.25724169,\n",
       "        0.65132878,  0.52777993])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50216311488543508"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49901758888801906"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3329"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '100', '11', '113', '12', '1200', '127', '12in', '13', '130k', '14', '15', '15m', '16', '17', '1795', '18', '18k', '19', '1901', '1970s', '1974', '1995', '19m', '1m', '1st', '20', '200', '2010', '2012', '2013', '2014', '2015', '2175026', '2206960', '24', '24m', '24th', '25', '250', '26', '27', '28', '280', '30', '300', '300k', '32', '35']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['working', 'works', 'world', 'worldwide', 'worms', 'worry', 'worse', 'worsens', 'would', 'wounded', 'wounding', 'woz', 'wozniak', 'wright', 'writer', 'writing', 'wrong', 'wrongly', 'wrote', 'wsj', 'wtc', 'wwdc', 'www', 'yang', 'year', 'years', 'yemen', 'yemeni', 'yes', 'yet', 'yeti', 'yields', 'yo', 'york', 'you', 'young', 'younger', 'youngest', 'your', 'yourselves', 'youtube', 'ypg', 'yum', 'zack', 'zehaf', 'zeppelin', 'zero', 'zeroes', 'zhejiang', 'été']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 142.,   80.,  113., ...,   10.,    6.,    6.],\n",
       "       [ 146.,   87.,  126., ...,    4.,    3.,    9.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3329)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 142.,   80.,  113., ...,   10.,    6.,    6.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 146.,   87.,  126., ...,    4.,    3.,    9.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>142.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>113.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>133.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       agree  disagree\n",
       "token                 \n",
       "000    142.0     146.0\n",
       "10      80.0      87.0\n",
       "100    113.0     126.0\n",
       "11     133.0     143.0\n",
       "113      2.0       2.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'agree':ham_token_count, 'disagree':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mälaren</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storage</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taibbi</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveller</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vet</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agree  disagree\n",
       "token                     \n",
       "mälaren      1.0       4.0\n",
       "storage      9.0       9.0\n",
       "taibbi      14.0      10.0\n",
       "traveller    3.0       2.0\n",
       "vet          5.0      10.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9388.,  9335.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mälaren</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storage</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taibbi</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveller</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vet</th>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agree  disagree\n",
       "token                     \n",
       "mälaren      2.0       5.0\n",
       "storage     10.0      10.0\n",
       "taibbi      15.0      11.0\n",
       "traveller    4.0       3.0\n",
       "vet          6.0      11.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['agree'] = tokens.agree + 1\n",
    "tokens['disagree'] = tokens.disagree + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mälaren</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storage</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taibbi</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveller</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vet</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              agree  disagree\n",
       "token                        \n",
       "mälaren    0.000213  0.000536\n",
       "storage    0.001065  0.001071\n",
       "taibbi     0.001598  0.001178\n",
       "traveller  0.000426  0.000321\n",
       "vet        0.000639  0.001178"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['agree'] = tokens.agree / nb.class_count_[0]\n",
    "tokens['disagree'] = tokens.disagree / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mälaren</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>2.514194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storage</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>1.005678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taibbi</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.737497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveller</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.754258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vet</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>1.843742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              agree  disagree  spam_ratio\n",
       "token                                    \n",
       "mälaren    0.000213  0.000536    2.514194\n",
       "storage    0.001065  0.001071    1.005678\n",
       "taibbi     0.001598  0.001178    0.737497\n",
       "traveller  0.000426  0.000321    0.754258\n",
       "vet        0.000639  0.001178    1.843742"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.disagree / tokens.agree\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wildest</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>9.051098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macklemorejoinedisis</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>7.039743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reaching</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>6.034065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traded</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>6.034065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misses</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>5.531227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>5.531227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ritual</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>5.531227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieved</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forty</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mirfield</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>works</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrote</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>5.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>4.525549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gallery</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>4.525549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crude</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>govt</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxes</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citi</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portal</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virility</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dustbin</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocket</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threw</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publishes</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>4.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whose</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>3.519871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.519871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.519871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweeting</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>3.519871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.287336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.287336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.287336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perth</th>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.274276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neal</th>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.274276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks</th>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.274276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alert</th>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.274276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayward</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kanye</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samuel</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mechanical</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15m</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignite</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gateway</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currently</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pundit</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiser</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.251419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failing</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.223484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many</th>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoilers</th>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tablet</th>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newest</th>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.201136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disconnects</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.167613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inaccurate</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.167613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wildly</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.167613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calls</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.143668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3329 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         agree  disagree  spam_ratio\n",
       "token                                               \n",
       "wildest               0.000107  0.000964    9.051098\n",
       "macklemorejoinedisis  0.000107  0.000750    7.039743\n",
       "reaching              0.000107  0.000643    6.034065\n",
       "traded                0.000107  0.000643    6.034065\n",
       "misses                0.000213  0.001178    5.531227\n",
       "annual                0.000213  0.001178    5.531227\n",
       "ritual                0.000213  0.001178    5.531227\n",
       "retrieved             0.000107  0.000536    5.028388\n",
       "forty                 0.000107  0.000536    5.028388\n",
       "mirfield              0.000107  0.000536    5.028388\n",
       "works                 0.000107  0.000536    5.028388\n",
       "wrote                 0.000107  0.000536    5.028388\n",
       "operation             0.000213  0.000964    4.525549\n",
       "gallery               0.000213  0.000964    4.525549\n",
       "crude                 0.000107  0.000428    4.022710\n",
       "550                   0.000107  0.000428    4.022710\n",
       "govt                  0.000107  0.000428    4.022710\n",
       "relaxes               0.000213  0.000857    4.022710\n",
       "citi                  0.000107  0.000428    4.022710\n",
       "portal                0.000107  0.000428    4.022710\n",
       "virility              0.000107  0.000428    4.022710\n",
       "dustbin               0.000213  0.000857    4.022710\n",
       "rocket                0.000107  0.000428    4.022710\n",
       "threw                 0.000107  0.000428    4.022710\n",
       "publishes             0.000107  0.000428    4.022710\n",
       "950                   0.000107  0.000428    4.022710\n",
       "whose                 0.000213  0.000750    3.519871\n",
       "space                 0.000426  0.001500    3.519871\n",
       "object                0.000426  0.001500    3.519871\n",
       "tweeting              0.000213  0.000750    3.519871\n",
       "...                        ...       ...         ...\n",
       "bedroom               0.000746  0.000214    0.287336\n",
       "su                    0.000746  0.000214    0.287336\n",
       "skills                0.000746  0.000214    0.287336\n",
       "perth                 0.001172  0.000321    0.274276\n",
       "neal                  0.001172  0.000321    0.274276\n",
       "thinks                0.001172  0.000321    0.274276\n",
       "alert                 0.001172  0.000321    0.274276\n",
       "wayward               0.000852  0.000214    0.251419\n",
       "kanye                 0.000852  0.000214    0.251419\n",
       "samuel                0.000426  0.000107    0.251419\n",
       "mechanical            0.000852  0.000214    0.251419\n",
       "15m                   0.000426  0.000107    0.251419\n",
       "ignite                0.000426  0.000107    0.251419\n",
       "global                0.000426  0.000107    0.251419\n",
       "gateway               0.000852  0.000214    0.251419\n",
       "currently             0.000852  0.000214    0.251419\n",
       "pundit                0.000852  0.000214    0.251419\n",
       "wiser                 0.000852  0.000214    0.251419\n",
       "failing               0.000959  0.000214    0.223484\n",
       "director              0.000533  0.000107    0.201136\n",
       "playing               0.001065  0.000214    0.201136\n",
       "many                  0.000533  0.000107    0.201136\n",
       "scores                0.001065  0.000214    0.201136\n",
       "spoilers              0.000533  0.000107    0.201136\n",
       "tablet                0.000533  0.000107    0.201136\n",
       "newest                0.000533  0.000107    0.201136\n",
       "disconnects           0.000639  0.000107    0.167613\n",
       "inaccurate            0.000639  0.000107    0.167613\n",
       "wildly                0.000639  0.000107    0.167613\n",
       "calls                 0.000746  0.000107    0.143668\n",
       "\n",
       "[3329 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
